{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gpt_personalized_keyword_generator import KeywordGenerator\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_generator = KeywordGenerator(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "We will generate the keywords. After that we will save them si if you want to generate new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Read = True\n",
    "w0 = 'cancer'   # Topic\n",
    "n0 = 40         # Keywords related with first topic \n",
    "n1 = 100        # Keywords related with subsequent topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Read == False:\n",
    "    L0 = [] #This is the dictionary for the first level\n",
    "    keys0 = kw_generator.kwds_prompt(w0,n0)\n",
    "    kwds0 = eval(keys0)\n",
    "    kwds0 = {**{w0:0},**kwds0}\n",
    "    L0.append(kwds0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Read == False:\n",
    "    correction_len = 35\n",
    "    for e, kwd in enumerate(L0[0]):\n",
    "        if e > len(L1):\n",
    "            print(kwd)\n",
    "            keys = kw_generator.kwds_prompt(kwd,n1)\n",
    "            try:\n",
    "                kwds = eval(keys)\n",
    "            except:\n",
    "                print(keys[-correction_len:])\n",
    "                solution = input(\"Enter a solution:\")\n",
    "                keys = keys[:-correction_len] + solution\n",
    "                kwds = eval(keys)\n",
    "            kwds = {**{kwd:0},**kwds}\n",
    "            L1.append(kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:4: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:4: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\{'\n",
      "C:\\Users\\danibacaicoa\\AppData\\Local\\Temp\\ipykernel_58636\\3235079148.py:4: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  file_name = f'Keywords_datasets\\{w0}_keywords_{fecha.year}{fecha.month:02d}{fecha.day:02d}.pickle'\n"
     ]
    }
   ],
   "source": [
    "if Read == False:\n",
    "    L = [L0,L1]\n",
    "    fecha = datetime.now()\n",
    "    file_name = f'Keywords_datasets\\{w0}_keywords_{fecha.year}{fecha.month:02d}{fecha.day:02d}.pickle'\n",
    "\n",
    "    # We could do it with:\n",
    "    f = open(file_name, 'wb')\n",
    "    pickle.dump(L, f)\n",
    "    f.close()\n",
    "\n",
    "    ##Or\n",
    "    #with open('data.pickle', 'wb') as f:\n",
    "    #    pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\danibacaicoa\\AppData\\Local\\Temp\\ipykernel_58636\\2377652600.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  f = open('Keywords_datasets\\cancer_keywords_20240417.pickle', 'rb')\n"
     ]
    }
   ],
   "source": [
    "if Read == True:\n",
    "    f = open('Keywords_datasets\\cancer_keywords_20240417.pickle', 'rb')\n",
    "    L = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    #with open('data.pickle', 'rb') as f:\n",
    "    #    loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(L[0]))\n",
    "print(len(L[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(L[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "165\n",
      "75\n",
      "79\n",
      "69\n",
      "75\n",
      "22\n",
      "74\n",
      "26\n",
      "104\n",
      "55\n",
      "32\n",
      "81\n",
      "26\n",
      "52\n",
      "59\n",
      "80\n",
      "174\n",
      "35\n",
      "76\n",
      "30\n",
      "92\n",
      "50\n",
      "64\n",
      "31\n",
      "131\n",
      "79\n",
      "88\n",
      "81\n",
      "57\n",
      "26\n",
      "93\n",
      "197\n",
      "75\n",
      "103\n",
      "85\n",
      "111\n",
      "103\n",
      "11\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "for dictionary in L[1]:\n",
    "    print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tumor': 0, 'cancer': 10, 'cells': 9, 'growth': 8, 'treatment': 7, 'metastasis': 6, 'biopsy': 5, 'mutation': 4, 'chemotherapy': 3, 'radiation': 2, 'prognosis': 1, 'oncogene': 0, 'apoptosis': 10, 'angiogenesis': 9, 'carcinoma': 8, 'malignant': 7, 'benign': 6, 'invasion': 5, 'immunotherapy': 4, 'tumor suppressor': 3, 'diagnosis': 2, 'risk factors': 1, 'genetics': 0, 'proliferation': 10, 'tumor markers': 9, 'surgery': 8, 'targeted therapy': 7, 'recurrence': 6, 'prostate': 10, 'lymph nodes': 4, 'melanoma': 7, 'glioblastoma': 2, 'leukemia': 1, 'sarcoma': 0, 'inflammation': 10, 'prevention': 9, 'screening': 8, 'breast': 6, 'lung': 5, 'colon': 4, 'pancreatic': 3, 'ovarian': 2, 'brain': 1, 'liver': 0, 'staging': 9, 'lymphoma': 8, 'tissue': 7, 'prostate-specific antigen': 6, 'hormone therapy': 5, 'biomarkers': 4, 'prostatectomy': 3, 'testicular': 2, 'bladder': 1, 'kidney': 0, 'metastatic': 10, 'tumor microenvironment': 0, 'clinical trials': 8, 'immunosuppression': 7, 'prognostic factors': 6, 'tumor heterogeneity': 5, 'microRNA': 4, 'epigenetics': 3}\n"
     ]
    }
   ],
   "source": [
    "print(L[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
